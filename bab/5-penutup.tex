\chapter{PENUTUP}
\label{chap:penutup}

% Ubah bagian-bagian berikut dengan isi dari penutup

\section{Kesimpulan}
\label{sec:kesimpulan}

Dari keseluruhan penelitian yang telah dilakukan, maka dapat dimabil beberapa kesimpulan sebagai berikut :

\begin{enumerate}[nolistsep]

  \item Semakin banyak dataset yang digunakan pada waktu \textit{pretrain} BERT, maka semakin akurat juga suatu model tersebut, hal ini terbukti oleh model \textit{indobert-base-p1} yang dilatih dengan 23 GB lebih data.
  \item Metode pemenggalan kata dengan hanya mengambil bagian awal dari suatu teks berhasil memperoleh tingkat akurasi yang lebih baik sebesar 3\% pada hampir seluruh metriks apabila dibandingkan dengan metode - metode pemenggalan teks lainnya. Hal ini karena pada berita berbahasa Indonesia, hampir semuanya diawali dengan \textit{lead} atau inti berita singkat, sehingga dengan mengambil bagian awal saja sudah memadai untuk melakukan klasifikasi.
  \item Penggunaan model BERT yang spesifik untuk bahasa Indonesia secara umum memiliki nilai akurasi yang lebih baik sebesar 10\% pada metriks \textit{precision} apabila dibandingkan dengan model multibahasa maupun bahasa Melayu dalam mendeteksi berita palsu berbahasa Indonesia.
  \item Walaupun sudah terdapat beberapa model lain yang merupakan turunan dari BERT itu sendiri, namun BERT masih merupakan model yang cukup bagus untuk klasifikasi teks, hal ini terlihat dari pengujian dimana BERT memiliki tingkat akurasi yang lebih baik sebesar 1\% dan waktu \textit{training} yang paling sedikit dengan hanya membutuhkan waktu 2 menit 3 detik.
  \item BERT adalah model yang sangat mudah terjadi \textit{overfit}, sehingga pengaturan parameter seperti dengan \textit{dropout} dan parameter \textit{freeze} akan membuat model lebih \textit{general} namun memiliki tingkat akurasi beberapa persen lebih rendah sebesar 5 - 6\% saja.

\end{enumerate}

\section{Saran}
\label{chap:saran}

Adapun dari penelitian ini terdapat beberapa saran dari penulis yang sekiranya dapat membantu untuk meningkatkan hasil dari penelitian ini, saran - saran tersebut adalah :

\begin{enumerate}[nolistsep]

  \item Dataset yang digunakan dalam penelitian ini masih dirasa kurang dan dapat diperbanyak lagi. Semakin banyak dataset yang digunakan semakin bagus pula tingkat akurasi modelnya.
  \item Dataset yang digunakan dalam penelitian ini adalah dataset yang diambil langsung dari situs - situs di internet. Walaupun situs - situs tersebut adalah resmi, namun keabsahan datanya masih harus diverifikasi lagi, lebih spesifik lagi, data dengan label hoaks masih harus diverifikasi lagi.
  \item Salah satu kelemahan BERT adalah jumlah token yang dapat diprosesnya dalam sekali waktu. Sudah terdapat penelitian lain hasil pengembangan dari BERT namun tidak memiliki limitasi jumlah token seperti BERT.
  \item Membuat sistem yang sudah terintegrasi sehingga memudahkan masyarakat dalam mendeteksi berita palsu.

\end{enumerate}
